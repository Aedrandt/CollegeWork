# -*- coding: utf-8 -*-
"""AhdanAITask.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17Ruf_JOeKlP9BjcnW44_oZhIS6RV7h7G
"""

# Langkah 1: Import Pustaka dan Dataset
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

iris = load_iris()
X = iris.data
y = iris.target

# Langkah 2: Preprocessing Data
encoder = OneHotEncoder(sparse=False)
y = encoder.fit_transform(y.reshape(-1, 1))
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Langkah 3: Membangun Model
model = Sequential([
    Dense(10, input_shape=(4,), activation='relu'),
    Dense(3, activation='softmax')
])

# Langkah 4: Melatih Model
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))

# Langkah 5: Evaluasi Model
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_test_classes = np.argmax(y_test, axis=1)

accuracy = accuracy_score(y_test_classes, y_pred_classes)
precision = precision_score(y_test_classes, y_pred_classes, average='macro')
recall = recall_score(y_test_classes, y_pred_classes, average='macro')
f1 = f1_score(y_test_classes, y_pred_classes, average='macro')

# Tampilkan metrik evaluasi
print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1-Score: {f1}')

# Plot kurva loss dan akurasi selama pelatihan
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.show()

# Langkah 6: Presentasi Hasil
# Tampilkan hasil evaluasi dalam bentuk tabel
results = pd.DataFrame({
    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],
    'Score': [accuracy, precision, recall, f1]
})
print(results)
8
# Interpretasi hasil yang diperoleh
print("Hasil evaluasi menunjukkan bahwa model memiliki akurasi, precision, recall,dan F1-score yang baik pada data uji, yang mengindikasikan kinerja yang baik dalam memprediksi kelas spesies iris.")

# Langkah 1: Import Pustaka dan Dataset
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc

# Load dataset Pima Indians Diabetes
url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'
column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']
data = pd.read_csv(url, header=None, names=column_names)

# Langkah 2: Preprocessing Data
# Pisahkan dataset menjadi fitur (X) dan label (y)
X = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

# Bagi dataset menjadi data latih dan data uji dengan rasio 80:20
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalisasi fitur menggunakan StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Langkah 3: Membangun Model
# Implementasikan model K-Nearest Neighbors menggunakan scikit-learn
knn = KNeighborsClassifier(n_neighbors=5)

# Langkah 4: Melatih Model
# Latih model pada data latih dan validasi pada data uji
knn.fit(X_train, y_train)

# Langkah 5: Evaluasi Model
# Prediksi pada data uji
y_pred = knn.predict(X_test)

# Evaluasi kinerja model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Hitung kurva ROC dan AUC
y_prob = knn.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

# Plot kurva ROC
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

# Langkah 6: Presentasi Hasil
# Tampilkan hasil evaluasi dalam bentuk tabel
results = pd.DataFrame({
    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC'],
    'Score': [accuracy, precision, recall, f1, roc_auc]
})
print(results)

# Interpretasi hasil yang diperoleh
print("Hasil evaluasi menunjukkan bahwa model KNN memiliki kinerja yang baik dalam mendeteksi penyakit diabetes dengan akurasi, precision, recall, F1-score, dan AUC yang cukup tinggi.")

# Langkah 1: Import Pustaka dan Dataset
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load dataset Boston Housing dari UCI Repository
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data"
column_names = [
    'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV'
]
data = pd.read_csv(url, delim_whitespace=True, header=None, names=column_names)

# Pisahkan dataset menjadi fitur (X) dan label (y)
X = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

# Bagi dataset menjadi data latih dan data uji dengan rasio 80:20
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Langkah 3: Membangun Model
# Implementasikan model Linear Regression menggunakan scikit-learn
model = LinearRegression()

# Langkah 4: Melatih Model
# Latih model pada data latih dan validasi pada data uji
model.fit(X_train, y_train)

# Langkah 5: Evaluasi Model
# Prediksi pada data uji
y_pred = model.predict(X_test)

# Evaluasi kinerja model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Plot scatter plot antara nilai aktual dan prediksi
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, edgecolors=(0, 0, 0))
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=4)
plt.xlabel('Nilai Aktual')
plt.ylabel('Nilai Prediksi')
plt.title('Scatter Plot antara Nilai Aktual dan Prediksi')
plt.show()

# Langkah 6: Presentasi Hasil
# Tampilkan hasil evaluasi dalam bentuk tabel
results = pd.DataFrame({
    'Metric': ['Mean Absolute Error', 'Mean Squared Error', 'R^2 Score'],
    'Score': [mae, mse, r2]
})
print(results)

# Interpretasi hasil yang diperoleh
print("Hasil evaluasi menunjukkan bahwa model Linear Regression memiliki nilai MAE, MSE, dan R^2 yang menunjukkan kinerja model dalam memprediksi harga rumah.")